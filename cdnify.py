#!/usr/bin/env python3

"""Upload assets to S3 and produce algobowl/lib/algocdn.py.

This gets called prior to building a wheel, that way we can remove assets from
the wheel and source distributions on PyPI.
"""

from pathlib import Path
import subprocess

import s3fs
import click

HERE = Path(__file__).resolve().parent


def write_py_out(f, url_map):
    print("# Auto-generated by cdnify.py", file=f)
    print(f"url_map = {url_map!r}", file=f)


@click.command()
@click.option("--access-key", envvar="S3_ACCESS_KEY", required=True)
@click.option("--secret-key", envvar="S3_SECRET_KEY", required=True)
@click.option("--bucket", envvar="S3_BUCKET", default="algocdn")
@click.option(
    "--endpoint-url",
    envvar="S3_ENDPOINT_URL",
    default="https://s3.us-west-004.backblazeb2.com",
)
@click.option(
    "--public-url-prefix",
    default="https://assets.algobowl.org/file/algocdn",
)
@click.option("--public-dir", type=Path, default=HERE / "algobowl" / "public")
@click.option("--py-out", type=Path, default=HERE / "algobowl" / "lib" / "algocdn.py")
def main(
    access_key, secret_key, bucket, endpoint_url, public_dir, public_url_prefix, py_out
):
    s3 = s3fs.S3FileSystem(endpoint_url=endpoint_url, key=access_key, secret=secret_key)
    url_map = {}
    assets_hash = subprocess.run(
        ["git", "log", "-n1", "--format=%H", "--", public_dir],
        stdout=subprocess.PIPE,
        encoding="utf-8",
        check=True,
    ).stdout.strip()

    for path in public_dir.glob("**/*"):
        if not path.is_file():
            continue
        relative_url = f"/{path.relative_to(public_dir)}"
        remote_path = f"{assets_hash}{relative_url}"
        s3_uri = f"s3://{bucket}/{remote_path}"
        if not s3.exists(s3_uri):
            click.echo(f"Upload {path} to {s3_uri}", err=True)
            s3.put_file(path, s3_uri)
        url_map[relative_url] = f"{public_url_prefix}/{remote_path}"

    with open(py_out, "w", encoding="utf-8") as f:
        write_py_out(f, url_map)


if __name__ == "__main__":
    main()
